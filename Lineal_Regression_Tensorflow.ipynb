{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresion Lineal en Tensorflow\n",
    "\n",
    "En este proyecto  trataremos predecir los precios de la casa utilizando regresion lineal y reducir el gradient.\n",
    "\n",
    "Ecuacion a utilizar:\n",
    "$ h(x) = wx +b$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "%load_ext tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    " # read data set\n",
    "data = np.load('C:\\R_File\\Master of Data Science\\Python\\Project\\proyecto_data\\proyecto_training_data.npy') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precio</th>\n",
       "      <th>Calif</th>\n",
       "      <th>fsqrt</th>\n",
       "      <th>trooms</th>\n",
       "      <th>yearbuilt</th>\n",
       "      <th>LotFrontage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>180.921196</td>\n",
       "      <td>6.099315</td>\n",
       "      <td>1.162627</td>\n",
       "      <td>6.517808</td>\n",
       "      <td>1971.267808</td>\n",
       "      <td>57.623288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>79.442503</td>\n",
       "      <td>1.382997</td>\n",
       "      <td>0.386588</td>\n",
       "      <td>1.625393</td>\n",
       "      <td>30.202904</td>\n",
       "      <td>34.664304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>34.900000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.334000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1872.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>129.975000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.882000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1954.000000</td>\n",
       "      <td>42.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>163.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.087000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1973.000000</td>\n",
       "      <td>63.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>214.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.391250</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>79.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>755.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.692000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>313.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            precio        Calif        fsqrt       trooms    yearbuilt  \\\n",
       "count  1460.000000  1460.000000  1460.000000  1460.000000  1460.000000   \n",
       "mean    180.921196     6.099315     1.162627     6.517808  1971.267808   \n",
       "std      79.442503     1.382997     0.386588     1.625393    30.202904   \n",
       "min      34.900000     1.000000     0.334000     2.000000  1872.000000   \n",
       "25%     129.975000     5.000000     0.882000     5.000000  1954.000000   \n",
       "50%     163.000000     6.000000     1.087000     6.000000  1973.000000   \n",
       "75%     214.000000     7.000000     1.391250     7.000000  2000.000000   \n",
       "max     755.000000    10.000000     4.692000    14.000000  2010.000000   \n",
       "\n",
       "       LotFrontage  \n",
       "count  1460.000000  \n",
       "mean     57.623288  \n",
       "std      34.664304  \n",
       "min       0.000000  \n",
       "25%      42.000000  \n",
       "50%      63.000000  \n",
       "75%      79.000000  \n",
       "max     313.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crear Dataframe  y normalizar los datos\n",
    "\n",
    "casadf = pd.DataFrame(data =data, columns = [\"precio\", \"Calif\", \"fsqrt\",\"trooms\",\"yearbuilt\",\"LotFrontage\"])\n",
    "casadf['precio']= casadf['precio']/1000\n",
    "casadf['fsqrt']= casadf['fsqrt']/1000\n",
    "casadf.fillna(0,inplace=True)\n",
    "casadf.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precio</th>\n",
       "      <th>Calif</th>\n",
       "      <th>fsqrt</th>\n",
       "      <th>trooms</th>\n",
       "      <th>yearbuilt</th>\n",
       "      <th>LotFrontage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precio</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.790982</td>\n",
       "      <td>0.605852</td>\n",
       "      <td>0.533723</td>\n",
       "      <td>0.522897</td>\n",
       "      <td>0.209624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Calif</th>\n",
       "      <td>0.790982</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.476224</td>\n",
       "      <td>0.427452</td>\n",
       "      <td>0.572323</td>\n",
       "      <td>0.176561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fsqrt</th>\n",
       "      <td>0.605852</td>\n",
       "      <td>0.476224</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.409516</td>\n",
       "      <td>0.281986</td>\n",
       "      <td>0.245181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trooms</th>\n",
       "      <td>0.533723</td>\n",
       "      <td>0.427452</td>\n",
       "      <td>0.409516</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.095589</td>\n",
       "      <td>0.221396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yearbuilt</th>\n",
       "      <td>0.522897</td>\n",
       "      <td>0.572323</td>\n",
       "      <td>0.281986</td>\n",
       "      <td>0.095589</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.036853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LotFrontage</th>\n",
       "      <td>0.209624</td>\n",
       "      <td>0.176561</td>\n",
       "      <td>0.245181</td>\n",
       "      <td>0.221396</td>\n",
       "      <td>0.036853</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               precio     Calif     fsqrt    trooms  yearbuilt  LotFrontage\n",
       "precio       1.000000  0.790982  0.605852  0.533723   0.522897     0.209624\n",
       "Calif        0.790982  1.000000  0.476224  0.427452   0.572323     0.176561\n",
       "fsqrt        0.605852  0.476224  1.000000  0.409516   0.281986     0.245181\n",
       "trooms       0.533723  0.427452  0.409516  1.000000   0.095589     0.221396\n",
       "yearbuilt    0.522897  0.572323  0.281986  0.095589   1.000000     0.036853\n",
       "LotFrontage  0.209624  0.176561  0.245181  0.221396   0.036853     1.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "casadf.corr(method='pearson', min_periods=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Correlation de Variables.**\n",
    "Basado la correlacion de los datos podemos indicar que:\n",
    "\n",
    "* ``` Calif ``` con un $R = 0.79$\n",
    "* ``` fsqrt ``` con un $R = 0.61$\n",
    "\n",
    "Son las mas predictivas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entrenamiento:  1187 , set de prueba:  273\n"
     ]
    }
   ],
   "source": [
    "#Random seed para reproducibilidad de los resultados\n",
    "\n",
    "np.random.seed(24)\n",
    "\n",
    "#Shuffle de datos\n",
    "df = casadf.sample(frac = 1)\n",
    "\n",
    "\n",
    "#Split Data entre entrenamiento y test\n",
    "\n",
    "msk = np.random.rand(len(df)) < 0.8\n",
    "\n",
    "train = df[msk]\n",
    "\n",
    "test = df[~msk]\n",
    "\n",
    "print('entrenamiento: ',len(train), ', set de prueba: ', len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo de regresión lineal mediante ***gradient descent***\n",
    "\n",
    "El modelo de regresión lineal se entrenará utilizando la siguiente función de costo.\n",
    "\n",
    "Función de costo:\n",
    "\n",
    "$C(w,b) = \\frac{1}{2m} \\sum_{i=1}^{m} (y_{i} − h(x_i))^2$\n",
    "\n",
    "donde:\n",
    "\n",
    "* $y_{i}$ : Valor real de cada dato en el dataset\n",
    "* $wx_{i}+b$ : Valor predecido por el modelo\n",
    "\n",
    "\n",
    "*Gradient descent*:\n",
    "\n",
    "$w = w - \\alpha \\frac{1}{n} \\sum_{i=1}^{n} (y_i - h(x_i))*m)$\n",
    "\n",
    "$b = b - \\alpha \\frac{1}{n} \\sum_{i=1}^{n} (y_i − h(x_i))$\n",
    "\n",
    "\n",
    "Los valores de $m$ y $b$ son actualizados iterativamente hasta minimizar el error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class regression_lineal:\n",
    "    def __init__ (self):\n",
    "        # vector.\n",
    "        self.w = tf.get_variable(\"weights\", dtype = tf.float32, shape = [1,2], initializer = tf.zeros_initializer())\n",
    "        \n",
    "    # Funcion para Y_hat\n",
    "    def __call__(self, x):\n",
    "        with tf.name_scope(\"model\"):\n",
    "            return tf.matmul(self.w,x)\n",
    "    # Funcion gradient descent\n",
    "    def update(self, x, y, lr):\n",
    "        with tf.name_scope(\"error\"):\n",
    "            error = self.error(x,y)\n",
    "            # Escalar\n",
    "            error_summary = tf.summary.scalar(\"ErrorSummary\", error)\n",
    "        gradient = tf.gradients(error, [self.w])\n",
    "        updated_w = tf.assign(self.w, self.w -lr * gradient[0])\n",
    "        return updated_w, error, error_summary\n",
    "    \n",
    "    # MSE\n",
    "    def error(self, x, y):\n",
    "        error = 1/2 * tf.reduce_mean(tf.math.square(y - self(x)))\n",
    "        return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train[\"precio\"]\n",
    "x = train[\"Calif\"]\n",
    "x = np.array([x, np.ones_like(x)], dtype = \"float64\")\n",
    "# Funcion para entrenamiento\n",
    "\n",
    "def training(lr, epochs, frecprint):\n",
    "    # String para definicion de experimento\n",
    "    string = './graphs/'+ datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") +\"_lr=\"+str(lr)+ \"_epochs=\"+str(epochs)\n",
    "\n",
    "    g = tf.Graph()\n",
    "    with g.as_default():\n",
    "        # Inicialización\n",
    "        modelo = regression_lineal()\n",
    "        # placeholders\n",
    "        tensorflow_x = tf.placeholder(tf.float32, [2,len(train[\"Calif\"])], \"tensorflow_x\")\n",
    "        tensorflow_y = tf.placeholder(tf.float32, [len(train[\"precio\"])], \"tensorflow_y\")\n",
    "        #  entrenamiento\n",
    "        update_parameters = modelo.update(tensorflow_x, tensorflow_y, lr)\n",
    "        \n",
    "        # tensorboard\n",
    "        writer = tf.summary.FileWriter(string, g)\n",
    "        \n",
    "        with tf.train.MonitoredSession() as session:\n",
    "            feed_dict = {tensorflow_x:x, tensorflow_y:y}\n",
    "            for i in range(epochs+1):\n",
    "                \n",
    "                # Entrenamiento\n",
    "                training = session.run(update_parameters, feed_dict = feed_dict)\n",
    "            \n",
    "                if (i)%frecprint == 0:\n",
    "                    # epocas\n",
    "                    weights = session.run(modelo.w, feed_dict = feed_dict)\n",
    "                    # visualizarlos en tensorboard\n",
    "                    writer.add_summary(training[2], i)\n",
    "                    print(\"Epoch: \", i, \"Weights: \", weights, \"Cost: \", training[1])\n",
    "                    print(\"-------------------------------------------------------------------------\")\n",
    "                    \n",
    "            writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\R_File\\Master of Data Science\\Python\\Grafo_Lineal_regression.png\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "filename = 'C:\\R_File\\Master of Data Science\\Python\\Grafo_Lineal_regression.png'\n",
    "print(os.path.abspath(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "Epoch:  0 Weights:  [[3.5573308 0.5412705]] Cost:  19256.78\n",
      "-------------------------------------------------------------------------\n",
      "Epoch:  100 Weights:  [[29.751112   3.2364564]] Cost:  1322.5784\n",
      "-------------------------------------------------------------------------\n",
      "Epoch:  200 Weights:  [[29.960613  1.894829]] Cost:  1316.4308\n",
      "-------------------------------------------------------------------------\n",
      "Epoch:  300 Weights:  [[30.167131   0.5718509]] Cost:  1310.4531\n",
      "-------------------------------------------------------------------------\n",
      "Epoch:  400 Weights:  [[30.370779  -0.7327246]] Cost:  1304.6404\n",
      "-------------------------------------------------------------------------\n",
      "Epoch:  500 Weights:  [[30.571594  -2.0191548]] Cost:  1298.9885\n",
      "-------------------------------------------------------------------------\n",
      "Epoch:  600 Weights:  [[30.769613 -3.287693]] Cost:  1293.4926\n",
      "-------------------------------------------------------------------------\n",
      "Epoch:  700 Weights:  [[30.964882  -4.5385857]] Cost:  1288.1484\n",
      "-------------------------------------------------------------------------\n",
      "Epoch:  800 Weights:  [[31.157433  -5.7720804]] Cost:  1282.9523\n",
      "-------------------------------------------------------------------------\n",
      "Epoch:  900 Weights:  [[31.347305 -6.988418]] Cost:  1277.8992\n",
      "-------------------------------------------------------------------------\n",
      "Epoch:  1000 Weights:  [[31.534536 -8.187838]] Cost:  1272.9858\n",
      "-------------------------------------------------------------------------\n",
      "Epoch:  1100 Weights:  [[31.719164 -9.370574]] Cost:  1268.2081\n",
      "-------------------------------------------------------------------------\n",
      "Epoch:  1200 Weights:  [[ 31.901224 -10.536859]] Cost:  1263.5625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch:  1300 Weights:  [[ 32.080746 -11.686919]] Cost:  1259.0454\n",
      "-------------------------------------------------------------------------\n",
      "Epoch:  1400 Weights:  [[ 32.257774 -12.820981]] Cost:  1254.6528\n",
      "-------------------------------------------------------------------------\n",
      "Epoch:  1500 Weights:  [[ 32.432346 -13.939267]] Cost:  1250.3816\n",
      "-------------------------------------------------------------------------\n",
      "Epoch:  1600 Weights:  [[ 32.60448  -15.041998]] Cost:  1246.2285\n",
      "-------------------------------------------------------------------------\n",
      "Epoch:  1700 Weights:  [[ 32.774223 -16.12939 ]] Cost:  1242.1903\n",
      "-------------------------------------------------------------------------\n",
      "Epoch:  1800 Weights:  [[ 32.94161 -17.20166]] Cost:  1238.2635\n",
      "-------------------------------------------------------------------------\n",
      "Epoch:  1900 Weights:  [[ 33.106667 -18.259016]] Cost:  1234.4448\n",
      "-------------------------------------------------------------------------\n",
      "Epoch:  2000 Weights:  [[ 33.269424 -19.301662]] Cost:  1230.7323\n",
      "-------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# test 1\n",
    "training(0.001, 2000,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "Epoch:  0 Weights:  [[47.43108    7.2169394]] Cost:  19256.78\n",
      "-------------------------------------------------------------------------\n",
      "Epoch:  1000 Weights:  [[ 42.45708  -78.158394]] Cost:  1105.4858\n",
      "-------------------------------------------------------------------------\n",
      "Epoch:  2000 Weights:  [[ 44.44563 -90.89719]] Cost:  1100.1705\n",
      "-------------------------------------------------------------------------\n",
      "Epoch:  3000 Weights:  [[ 44.752357 -92.8621  ]] Cost:  1100.0441\n",
      "-------------------------------------------------------------------------\n",
      "Epoch:  4000 Weights:  [[ 44.79967  -93.165215]] Cost:  1100.0413\n",
      "-------------------------------------------------------------------------\n",
      "Epoch:  5000 Weights:  [[ 44.806953 -93.21182 ]] Cost:  1100.041\n",
      "-------------------------------------------------------------------------\n",
      "Epoch:  6000 Weights:  [[ 44.80797 -93.21834]] Cost:  1100.0409\n",
      "-------------------------------------------------------------------------\n",
      "Epoch:  7000 Weights:  [[ 44.80797 -93.21834]] Cost:  1100.0409\n",
      "-------------------------------------------------------------------------\n",
      "Epoch:  8000 Weights:  [[ 44.80797 -93.21834]] Cost:  1100.0409\n",
      "-------------------------------------------------------------------------\n",
      "Epoch:  9000 Weights:  [[ 44.80797 -93.21834]] Cost:  1100.0409\n",
      "-------------------------------------------------------------------------\n",
      "Epoch:  10000 Weights:  [[ 44.80797 -93.21834]] Cost:  1100.0409\n",
      "-------------------------------------------------------------------------\n",
      "Epoch:  11000 Weights:  [[ 44.80797 -93.21834]] Cost:  1100.0409\n",
      "-------------------------------------------------------------------------\n",
      "Epoch:  12000 Weights:  [[ 44.80797 -93.21834]] Cost:  1100.0409\n",
      "-------------------------------------------------------------------------\n",
      "Epoch:  13000 Weights:  [[ 44.80797 -93.21834]] Cost:  1100.0409\n",
      "-------------------------------------------------------------------------\n",
      "Epoch:  14000 Weights:  [[ 44.80797 -93.21834]] Cost:  1100.0409\n",
      "-------------------------------------------------------------------------\n",
      "Epoch:  15000 Weights:  [[ 44.80797 -93.21834]] Cost:  1100.0409\n",
      "-------------------------------------------------------------------------\n",
      "Epoch:  16000 Weights:  [[ 44.80797 -93.21834]] Cost:  1100.0409\n",
      "-------------------------------------------------------------------------\n",
      "Epoch:  17000 Weights:  [[ 44.80797 -93.21834]] Cost:  1100.0409\n",
      "-------------------------------------------------------------------------\n",
      "Epoch:  18000 Weights:  [[ 44.80797 -93.21834]] Cost:  1100.0409\n",
      "-------------------------------------------------------------------------\n",
      "Epoch:  19000 Weights:  [[ 44.80797 -93.21834]] Cost:  1100.0409\n",
      "-------------------------------------------------------------------------\n",
      "Epoch:  20000 Weights:  [[ 44.80797 -93.21834]] Cost:  1100.0409\n",
      "-------------------------------------------------------------------------\n",
      "Epoch:  21000 Weights:  [[ 44.80797 -93.21834]] Cost:  1100.0409\n",
      "-------------------------------------------------------------------------\n",
      "Epoch:  22000 Weights:  [[ 44.80797 -93.21834]] Cost:  1100.0409\n",
      "-------------------------------------------------------------------------\n",
      "Epoch:  23000 Weights:  [[ 44.80797 -93.21834]] Cost:  1100.0409\n",
      "-------------------------------------------------------------------------\n",
      "Epoch:  24000 Weights:  [[ 44.80797 -93.21834]] Cost:  1100.0409\n",
      "-------------------------------------------------------------------------\n",
      "Epoch:  25000 Weights:  [[ 44.80797 -93.21834]] Cost:  1100.0409\n",
      "-------------------------------------------------------------------------\n",
      "Epoch:  26000 Weights:  [[ 44.80797 -93.21834]] Cost:  1100.0409\n",
      "-------------------------------------------------------------------------\n",
      "Epoch:  27000 Weights:  [[ 44.80797 -93.21834]] Cost:  1100.0409\n",
      "-------------------------------------------------------------------------\n",
      "Epoch:  28000 Weights:  [[ 44.80797 -93.21834]] Cost:  1100.0409\n",
      "-------------------------------------------------------------------------\n",
      "Epoch:  29000 Weights:  [[ 44.80797 -93.21834]] Cost:  1100.0409\n",
      "-------------------------------------------------------------------------\n",
      "Epoch:  30000 Weights:  [[ 44.80797 -93.21834]] Cost:  1100.0409\n",
      "-------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# test 2\n",
    "training(0.02, 2000,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "Epoch:  0 Weights:  [[47.43108    7.2169394]] Cost:  19256.78\n",
      "-------------------------------------------------------------------------\n",
      "Epoch:  1000 Weights:  [[ 42.45708  -78.158394]] Cost:  1105.4858\n",
      "-------------------------------------------------------------------------\n",
      "Epoch:  2000 Weights:  [[ 44.44563 -90.89719]] Cost:  1100.1705\n",
      "-------------------------------------------------------------------------\n",
      "Epoch:  3000 Weights:  [[ 44.752357 -92.8621  ]] Cost:  1100.0441\n",
      "-------------------------------------------------------------------------\n",
      "Epoch:  4000 Weights:  [[ 44.79967  -93.165215]] Cost:  1100.0413\n",
      "-------------------------------------------------------------------------\n",
      "Epoch:  5000 Weights:  [[ 44.806953 -93.21182 ]] Cost:  1100.041\n",
      "-------------------------------------------------------------------------\n",
      "Epoch:  6000 Weights:  [[ 44.80797 -93.21834]] Cost:  1100.0409\n",
      "-------------------------------------------------------------------------\n",
      "Epoch:  7000 Weights:  [[ 44.80797 -93.21834]] Cost:  1100.0409\n",
      "-------------------------------------------------------------------------\n",
      "Epoch:  8000 Weights:  [[ 44.80797 -93.21834]] Cost:  1100.0409\n",
      "-------------------------------------------------------------------------\n",
      "Epoch:  9000 Weights:  [[ 44.80797 -93.21834]] Cost:  1100.0409\n",
      "-------------------------------------------------------------------------\n",
      "Epoch:  10000 Weights:  [[ 44.80797 -93.21834]] Cost:  1100.0409\n",
      "-------------------------------------------------------------------------\n",
      "Epoch:  11000 Weights:  [[ 44.80797 -93.21834]] Cost:  1100.0409\n",
      "-------------------------------------------------------------------------\n",
      "Epoch:  12000 Weights:  [[ 44.80797 -93.21834]] Cost:  1100.0409\n",
      "-------------------------------------------------------------------------\n",
      "Epoch:  13000 Weights:  [[ 44.80797 -93.21834]] Cost:  1100.0409\n",
      "-------------------------------------------------------------------------\n",
      "Epoch:  14000 Weights:  [[ 44.80797 -93.21834]] Cost:  1100.0409\n",
      "-------------------------------------------------------------------------\n",
      "Epoch:  15000 Weights:  [[ 44.80797 -93.21834]] Cost:  1100.0409\n",
      "-------------------------------------------------------------------------\n",
      "Epoch:  16000 Weights:  [[ 44.80797 -93.21834]] Cost:  1100.0409\n",
      "-------------------------------------------------------------------------\n",
      "Epoch:  17000 Weights:  [[ 44.80797 -93.21834]] Cost:  1100.0409\n",
      "-------------------------------------------------------------------------\n",
      "Epoch:  18000 Weights:  [[ 44.80797 -93.21834]] Cost:  1100.0409\n",
      "-------------------------------------------------------------------------\n",
      "Epoch:  19000 Weights:  [[ 44.80797 -93.21834]] Cost:  1100.0409\n",
      "-------------------------------------------------------------------------\n",
      "Epoch:  20000 Weights:  [[ 44.80797 -93.21834]] Cost:  1100.0409\n",
      "-------------------------------------------------------------------------\n",
      "Epoch:  21000 Weights:  [[ 44.80797 -93.21834]] Cost:  1100.0409\n",
      "-------------------------------------------------------------------------\n",
      "Epoch:  22000 Weights:  [[ 44.80797 -93.21834]] Cost:  1100.0409\n",
      "-------------------------------------------------------------------------\n",
      "Epoch:  23000 Weights:  [[ 44.80797 -93.21834]] Cost:  1100.0409\n",
      "-------------------------------------------------------------------------\n",
      "Epoch:  24000 Weights:  [[ 44.80797 -93.21834]] Cost:  1100.0409\n",
      "-------------------------------------------------------------------------\n",
      "Epoch:  25000 Weights:  [[ 44.80797 -93.21834]] Cost:  1100.0409\n",
      "-------------------------------------------------------------------------\n",
      "Epoch:  26000 Weights:  [[ 44.80797 -93.21834]] Cost:  1100.0409\n",
      "-------------------------------------------------------------------------\n",
      "Epoch:  27000 Weights:  [[ 44.80797 -93.21834]] Cost:  1100.0409\n",
      "-------------------------------------------------------------------------\n",
      "Epoch:  28000 Weights:  [[ 44.80797 -93.21834]] Cost:  1100.0409\n",
      "-------------------------------------------------------------------------\n",
      "Epoch:  29000 Weights:  [[ 44.80797 -93.21834]] Cost:  1100.0409\n",
      "-------------------------------------------------------------------------\n",
      "Epoch:  30000 Weights:  [[ 44.80797 -93.21834]] Cost:  1100.0409\n",
      "-------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# test 3\n",
    "training(0.03, 2000,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Timed out waiting for TensorBoard to start. It may still be running as pid 13060."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test 4\n",
    "training(0.04, 2000,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test 5\n",
    "training(0.004, 2000,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 5224), started 3 days, 23:16:25 ago. (Use '!kill 5224' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-498958261b04f2c7\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-498958261b04f2c7\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir ./graphs  --port 6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
